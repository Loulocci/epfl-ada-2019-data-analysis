{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Project : Dunnhumby dataset, Tell me what you buy and I will tell you who you are\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Abstract\" data-toc-modified-id=\"Abstract-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Abstract</a></span></li><li><span><a href=\"#Documentation-of-built-in-functions:\" data-toc-modified-id=\"Documentation-of-built-in-functions:-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Documentation of built in functions:</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Functions-used-on-demographics:\" data-toc-modified-id=\"Functions-used-on-demographics:-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Functions used on demographics:</a></span></li><li><span><a href=\"#Functions-used-to-create-plots:\" data-toc-modified-id=\"Functions-used-to-create-plots:-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Functions used to create plots:</a></span></li><li><span><a href=\"#Functions-used-on-transactions:\" data-toc-modified-id=\"Functions-used-on-transactions:-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Functions used on transactions:</a></span></li><li><span><a href=\"#Machine-learning-functions:\" data-toc-modified-id=\"Machine-learning-functions:-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>Machine learning functions:</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-clean-up-and-overview-of-information-available:\" data-toc-modified-id=\"Data-clean-up-and-overview-of-information-available:-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data clean up and overview of information available:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Demographic-data:\" data-toc-modified-id=\"Demographic-data:-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Demographic data:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Demographic-categories:\" data-toc-modified-id=\"Demographic-categories:-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Demographic categories:</a></span></li><li><span><a href=\"#Cleaning-up-household-categories:\" data-toc-modified-id=\"Cleaning-up-household-categories:-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Cleaning up household categories:</a></span></li><li><span><a href=\"#Demographic-distributions:\" data-toc-modified-id=\"Demographic-distributions:-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Demographic distributions:</a></span></li></ul></li><li><span><a href=\"#Product-data:\" data-toc-modified-id=\"Product-data:-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Product data:</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Number-of-products:\" data-toc-modified-id=\"Number-of-products:-3.2.0.1\"><span class=\"toc-item-num\">3.2.0.1&nbsp;&nbsp;</span>Number of products:</a></span></li><li><span><a href=\"#Product-departments:\" data-toc-modified-id=\"Product-departments:-3.2.0.2\"><span class=\"toc-item-num\">3.2.0.2&nbsp;&nbsp;</span>Product departments:</a></span></li></ul></li></ul></li><li><span><a href=\"#Transaction-data:\" data-toc-modified-id=\"Transaction-data:-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Transaction data:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quick-overview:\" data-toc-modified-id=\"Quick-overview:-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Quick overview:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-total-transactions:\" data-toc-modified-id=\"Number-of-total-transactions:-3.3.1.1\"><span class=\"toc-item-num\">3.3.1.1&nbsp;&nbsp;</span>Number of total transactions:</a></span></li><li><span><a href=\"#Number-of-total-purchase-occasions:\" data-toc-modified-id=\"Number-of-total-purchase-occasions:-3.3.1.2\"><span class=\"toc-item-num\">3.3.1.2&nbsp;&nbsp;</span>Number of total purchase occasions:</a></span></li><li><span><a href=\"#Number-of-households-in-transaction-dataset:\" data-toc-modified-id=\"Number-of-households-in-transaction-dataset:-3.3.1.3\"><span class=\"toc-item-num\">3.3.1.3&nbsp;&nbsp;</span>Number of households in transaction dataset:</a></span></li></ul></li><li><span><a href=\"#Favored-product-departments-and-labels:\" data-toc-modified-id=\"Favored-product-departments-and-labels:-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Favored product departments and labels:</a></span></li><li><span><a href=\"#Shopping-frequencies:\" data-toc-modified-id=\"Shopping-frequencies:-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>Shopping frequencies:</a></span></li><li><span><a href=\"#Participation-rate-in-the-study:\" data-toc-modified-id=\"Participation-rate-in-the-study:-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>Participation rate in the study:</a></span></li><li><span><a href=\"#Household-spending:\" data-toc-modified-id=\"Household-spending:-3.3.5\"><span class=\"toc-item-num\">3.3.5&nbsp;&nbsp;</span>Household spending:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Yearly-spending:\" data-toc-modified-id=\"Yearly-spending:-3.3.5.1\"><span class=\"toc-item-num\">3.3.5.1&nbsp;&nbsp;</span>Yearly spending:</a></span></li><li><span><a href=\"#Weekly-spending:\" data-toc-modified-id=\"Weekly-spending:-3.3.5.2\"><span class=\"toc-item-num\">3.3.5.2&nbsp;&nbsp;</span>Weekly spending:</a></span></li></ul></li><li><span><a href=\"#Average-spending-versus-income:\" data-toc-modified-id=\"Average-spending-versus-income:-3.3.6\"><span class=\"toc-item-num\">3.3.6&nbsp;&nbsp;</span>Average spending versus income:</a></span></li><li><span><a href=\"#&quot;Loyal&quot;-shoppers-?\" data-toc-modified-id=\"&quot;Loyal&quot;-shoppers-?-3.3.7\"><span class=\"toc-item-num\">3.3.7&nbsp;&nbsp;</span>\"Loyal\" shoppers ?</a></span></li></ul></li></ul></li><li><span><a href=\"#Shopping-trends-and-correlations:\" data-toc-modified-id=\"Shopping-trends-and-correlations:-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Shopping trends and correlations:</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Prepare-data-for-correlation-calulcations:\" data-toc-modified-id=\"Prepare-data-for-correlation-calulcations:-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Prepare data for correlation calulcations:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Weekly-purchases.\" data-toc-modified-id=\"Weekly-purchases.-4.0.1.1\"><span class=\"toc-item-num\">4.0.1.1&nbsp;&nbsp;</span>Weekly purchases.</a></span></li><li><span><a href=\"#Weekly-purchases-and-demographic-information:\" data-toc-modified-id=\"Weekly-purchases-and-demographic-information:-4.0.1.2\"><span class=\"toc-item-num\">4.0.1.2&nbsp;&nbsp;</span>Weekly purchases and demographic information:</a></span></li></ul></li><li><span><a href=\"#Correlation-between-transactions-and-demographic-information:\" data-toc-modified-id=\"Correlation-between-transactions-and-demographic-information:-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Correlation between transactions and demographic information:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Plots-for-correlation-between-number-of-kids-and-household-size-and-marital-status-and-household-size:\" data-toc-modified-id=\"Plots-for-correlation-between-number-of-kids-and-household-size-and-marital-status-and-household-size:-4.0.2.1\"><span class=\"toc-item-num\">4.0.2.1&nbsp;&nbsp;</span>Plots for correlation between number of kids and household size and marital status and household size:</a></span></li><li><span><a href=\"#Comment:\" data-toc-modified-id=\"Comment:-4.0.2.2\"><span class=\"toc-item-num\">4.0.2.2&nbsp;&nbsp;</span>Comment:</a></span></li></ul></li><li><span><a href=\"#Decision-trees-and-random-forests:\" data-toc-modified-id=\"Decision-trees-and-random-forests:-4.0.3\"><span class=\"toc-item-num\">4.0.3&nbsp;&nbsp;</span>Decision trees and random forests:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Comment:\" data-toc-modified-id=\"Comment:-4.0.3.1\"><span class=\"toc-item-num\">4.0.3.1&nbsp;&nbsp;</span>Comment:</a></span></li><li><span><a href=\"#Visualization-of-the-decision-trees\" data-toc-modified-id=\"Visualization-of-the-decision-trees-4.0.3.2\"><span class=\"toc-item-num\">4.0.3.2&nbsp;&nbsp;</span>Visualization of the decision trees</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "We would like to analyse the Dunnhumby dataset. Living in a time and age where every piece of our data is stored and analysed; and being active consumers ourselves, we would like to see what informations retail chains can gather and infer about us knowing only our shopping habits. As transactions over two years of several households and their basic demographic profiles are provided, we want to see if there are any links and correlations between specific demographics (e.g. marital status, income, number of children, etc) and purchase patterns. Furthermore, if time permits it, we want to see if we can create a model predicting a consumer demographic profile from their shopping. Thus, we would like to see how \"easy\" and how precise it actually is for retailers to infer who their customer is by what they buy and target them with specific marketing. Basically, we want to know how much of a target we actually\n",
    "are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research questions:** \n",
    "- What are the main shopping trends that we can identify in this data ?\n",
    "- Can we relate shopping trends to specific demographic parameters ?\n",
    "- Can we predict some of these demographic parameters (age, marital statute etc) with knowing the household's habbits?\n",
    "- In the opposite way, can we predict household consumption behaviour with knowing its characteristics?\n",
    "- What accuracy in consumption prediction can the retailer obtain from a simple profile information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#Functions we created:\n",
    "from modules import dem_fx\n",
    "from modules import transaction_fx as trns\n",
    "from modules import plot_functions as plt_fx\n",
    "from modules import ml_functions as ml_fx\n",
    "from modules import time_fx as tm_fx\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "#Allows reload of modules:\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation of built in functions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we built several functions and put them in the doc folder. Please find below their documentation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions used on demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dem_fx.order_hh_dem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions used to create plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt_fx.cat_count_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt_fx.corr_function_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt_fx.double_categorical_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt_fx.double_plot_box_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt_fx.pair_corr_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt_fx.plot_box_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt_fx.plot_demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions used on transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trns.bud_total_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trns.correlation_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trns.cramers_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trns.create_weekly_cart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trns.df_weekly_spending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trns.mean_yearly_spending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trns.spending_per_household_per_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trns.trans_per_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ml_fx.decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ml_fx.multiclass_roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ml_fx.random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data clean up and overview of information available:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dunnhumby dataset contains household level transactions over two years from a group of 2,500 households who are frequent shoppers at a retailer. It contains all of each households' purchases, not just those from a limited number of categories. For certain households (around 800), demographic information as well as direct marketing contact history are included. We have a look at a few samples from each table: \n",
    "As we said in the description of our project, we are going to concentrate on 3 of the 8 tables :\n",
    "- hh_demographic.csv\n",
    "- transaction_data.csv\n",
    "- product.csv\n",
    "In this first step, we want to load the data, and prepare it for the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data: \n",
    "hh_demographic = pd.read_csv(\n",
    "    '../data/dunnhumby_complete_csv/hh_demographic.csv', sep=',')\n",
    "\n",
    "transaction_data = pd.read_csv(\n",
    "    '../data/dunnhumby_complete_csv/transaction_data.csv', sep=',')\n",
    "\n",
    "product = pd.read_csv('../data/dunnhumby_complete_csv/product.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographic data: \n",
    "Demographic info for a certain portion of households. The dataset contains only the data for 801 households of 2500 though. The rest could not be acquired. The attributes of the dataset are the following: \n",
    " \n",
    "- HOUSEHOLD_KEY : identifies each household, **unique**\n",
    "- AGE_DES: estimated age range\n",
    "- MARITAL_STATUS_CODE: A (Married), B (Single), C (Unknown)\n",
    "- INCOME_DESC : Household income\n",
    "- HOMEOWNER_DESC: Homeowner, renter, etc\n",
    "- HH_COMP_DEC: Household composition\n",
    "- HOUSEHOLD_SIZE_DESC: Size of household up to 5+ \n",
    "- KID_CATEGORY_DESC: Number of children present up to 3+ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at a few samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographic categories:\n",
    "The categories of available information are the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Age: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are %d age categories\" %\n",
    "      len(hh_demographic['AGE_DESC'].unique()))\n",
    "print(\"The different categories are:\", hh_demographic['AGE_DESC'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Income: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are %d income categories\" %\n",
    "      len(hh_demographic['INCOME_DESC'].unique()))\n",
    "print(\"The different categories are:\", hh_demographic['INCOME_DESC'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Homeowners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are %d homeowner categories\" %\n",
    "      len(hh_demographic['HOMEOWNER_DESC'].unique()))\n",
    "print(\"The different categories are:\",\n",
    "      hh_demographic['HOMEOWNER_DESC'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Household composition: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are %d household composition categories\" %\n",
    "      len(hh_demographic['HH_COMP_DESC'].unique()))\n",
    "print(\"The different categories are:\", hh_demographic['HH_COMP_DESC'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Household size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are %d household size categories\" %\n",
    "      len(hh_demographic['HOUSEHOLD_SIZE_DESC'].unique()))\n",
    "print(\"The different categories are:\",\n",
    "      hh_demographic['HOUSEHOLD_SIZE_DESC'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Kids number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are %d kid number categories\" %\n",
    "      len(hh_demographic['KID_CATEGORY_DESC'].unique()))\n",
    "print(\"The different categories are:\",\n",
    "      hh_demographic['KID_CATEGORY_DESC'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Marital status:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are %d marital status categories\" %\n",
    "      len(hh_demographic['MARITAL_STATUS_CODE'].unique()))\n",
    "print(\"The different categories are:\",\n",
    "      hh_demographic['MARITAL_STATUS_CODE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we change the marital status to a more intuitive one, setting to M the married entries and to S the singles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic.loc[hh_demographic['MARITAL_STATUS_CODE'] == 'A', 'MARITAL_STATUS_CODE'] = 'M'\n",
    "hh_demographic.loc[hh_demographic['MARITAL_STATUS_CODE'] == 'B', 'MARITAL_STATUS_CODE'] = 'S'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning up household categories:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three variables related to each other: *household composition*, *household size* and *number of kids*. Thus, we need to see if the information between them makes sens (e.g. if the number of kids corresponds to the correct household size, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first going to look what kind of values are available for each possible household composition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hh_composition in hh_demographic['HH_COMP_DESC'].unique():\n",
    "    if hh_composition == \"2 Adults No Kids\" or hh_composition == \"2 Adults Kids\":\n",
    "        continue\n",
    "    print(\"Looking at the household composition:\", hh_composition)\n",
    "    hh_demographic_current_composition = hh_demographic[\n",
    "        hh_demographic['HH_COMP_DESC'] == hh_composition]\n",
    "    print(\"Household size unique information:\",\n",
    "          hh_demographic_current_composition['HOUSEHOLD_SIZE_DESC'].unique())\n",
    "    print(\"Kids number unique information:\",\n",
    "          hh_demographic_current_composition['KID_CATEGORY_DESC'].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already see some inconsistencies. For example, a household of a single female can hardly be a household of size two. Except if she has kids but then she should be in a household of \"1 Adult Kids\". The same applies for the other types. This needs to be corrected before we proceed any further. For this we need to know which entries are wrong so we take a closer look at each household composition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Closer look at \"1 Adult Kids\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_composition = \"1 Adult Kids\"\n",
    "hh_demographic_1adultkids = hh_demographic[hh_demographic['HH_COMP_DESC'] ==\n",
    "                                           hh_composition]\n",
    "\n",
    "for household_size in hh_demographic_1adultkids['HOUSEHOLD_SIZE_DESC'].unique():\n",
    "    hh_demographic_1adultkids_size = hh_demographic_1adultkids[\n",
    "        hh_demographic_1adultkids['HOUSEHOLD_SIZE_DESC'] == household_size]\n",
    "\n",
    "    print(f\"For household of size {household_size}, with 1 adult, there are\",\n",
    "          hh_demographic_1adultkids_size['KID_CATEGORY_DESC'].unique(),\n",
    "          \"kid categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are inconsistencies when the household size is of 3 or 4 units. Let's explore these further:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Household of 3 units:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic_1adultkids[\n",
    "    (hh_demographic_1adultkids['HOUSEHOLD_SIZE_DESC'] == '3')\n",
    "    & (hh_demographic_1adultkids['KID_CATEGORY_DESC'] == '1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there are entries where the composition is *1 Adult Kids*, the household size is 3 and the number of kids is 1. This means one of the following: there is one more person living in the house, the household size is wrong or the composition is wrong.<br>\n",
    "However, we  notice that all of these entries have a marital status M, which stands for married. We can assume then that the composition is wrong and there is an actual couple living in the house, with 1 kid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Household of 4 units:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic_1adultkids[\n",
    "    (hh_demographic_1adultkids['HOUSEHOLD_SIZE_DESC'] == '4')\n",
    "    & (hh_demographic_1adultkids['KID_CATEGORY_DESC'] == '2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For household size of 4, the same as for 3 stands. Again the household composition is probably wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Closer look at \"Single Male/Female\": "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, the household should not be bigger than 1. So we look at the marital status of households of size 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_composition = \"Single Female\"\n",
    "\n",
    "hh_demographic_singlefemale_size2 = hh_demographic[\n",
    "    hh_demographic['HH_COMP_DESC'] == hh_composition]\n",
    "\n",
    "hh_demographic_singlefemale_size2 = hh_demographic_singlefemale_size2[\n",
    "    hh_demographic_singlefemale_size2['HOUSEHOLD_SIZE_DESC'] == '2']\n",
    "\n",
    "print(hh_demographic_singlefemale_size2['MARITAL_STATUS_CODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_composition = \"Single Male\"\n",
    "\n",
    "hh_demographic_singlemale_size2 = hh_demographic[hh_demographic['HH_COMP_DESC']\n",
    "                                                 == hh_composition]\n",
    "\n",
    "hh_demographic_singlemale_size2 = hh_demographic_singlemale_size2[\n",
    "    hh_demographic_singlemale_size2['HOUSEHOLD_SIZE_DESC'] == '2']\n",
    "\n",
    "print(hh_demographic_singlemale_size2['MARITAL_STATUS_CODE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it looks like they are married and not single and that the household composition is wrong.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Coherence between marital status, number of kids and  household size:\n",
    "We now want to check if the marital status, the number of kids and the household size are always coherent with each others. If it is, then we can assume that the household composition information is sometimes wrong. Hence, we can correct this parameter or just discard it, since it does not carry more information with respect to the other three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marital_status in np.sort(hh_demographic['MARITAL_STATUS_CODE'].unique()):\n",
    "    print(\"Marital status:\", marital_status)\n",
    "    \n",
    "    hh_demographic_current_marital = hh_demographic[\n",
    "        hh_demographic['MARITAL_STATUS_CODE'] == marital_status]\n",
    "    \n",
    "    print(\n",
    "        hh_demographic_current_marital.groupby(\n",
    "            ['HH_COMP_DESC', 'HOUSEHOLD_SIZE_DESC',\n",
    "             'KID_CATEGORY_DESC']).size())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that: \n",
    "- the marital status is always coherent with the household size and the number of kids. Combined with the findings above, we can say that in these cases where the household composition is wrong, we will just discard that information.\n",
    "- we have some incongruities in the household size / number of kids when the marital status is Single, so we discard these entries.\n",
    "- if the marital status is *Unknown*, we fall back on the household size / number of children information and we give the corresponding marital status, when it makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Actually removing the inconsistencies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic_fxd = hh_demographic.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the entries marked as Single with inconsistencies in the household size / number of kids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropindex = hh_demographic_fxd.index[\n",
    "    (hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'S')\n",
    "    & (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '2') &\n",
    "    (hh_demographic_fxd['KID_CATEGORY_DESC'] == 'None/Unknown')].tolist()\n",
    "\n",
    "dropindex += hh_demographic_fxd.index[\n",
    "    (hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'S')\n",
    "    & (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '3') &\n",
    "    (hh_demographic_fxd['KID_CATEGORY_DESC'] == '1')].tolist()\n",
    "\n",
    "dropindex += hh_demographic_fxd.index[\n",
    "    (hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'S')\n",
    "    & (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '4') &\n",
    "    (hh_demographic_fxd['KID_CATEGORY_DESC'] == '2')].tolist()\n",
    "\n",
    "print(dropindex)\n",
    "print(len(dropindex), \"entries dropped.\")\n",
    "\n",
    "hh_demographic_fxd.drop(dropindex, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning the correct marital status to the entries marked as Unknown, when the household size and the number of children are coherent with each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic_fxd.loc[(hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'U') &\n",
    "                       (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '3') &\n",
    "                       (hh_demographic_fxd['KID_CATEGORY_DESC'] == '1'\n",
    "                        ), 'MARITAL_STATUS_CODE'] = 'M'\n",
    "\n",
    "hh_demographic_fxd.loc[(hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'U') &\n",
    "                       (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '4') &\n",
    "                       (hh_demographic_fxd['KID_CATEGORY_DESC'] == '2'\n",
    "                        ), 'MARITAL_STATUS_CODE'] = 'M'\n",
    "\n",
    "hh_demographic_fxd.loc[(hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'U') &\n",
    "                       (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '2') &\n",
    "                       (hh_demographic_fxd['KID_CATEGORY_DESC'] ==\n",
    "                        'None/Unknown'), 'MARITAL_STATUS_CODE'] = 'M'\n",
    "\n",
    "hh_demographic_fxd.loc[(hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'U') &\n",
    "                       (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '2') &\n",
    "                       (hh_demographic_fxd['KID_CATEGORY_DESC'] == '1'\n",
    "                        ), 'MARITAL_STATUS_CODE'] = 'S'\n",
    "\n",
    "hh_demographic_fxd.loc[(hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'U') &\n",
    "                       (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '3') &\n",
    "                       (hh_demographic_fxd['KID_CATEGORY_DESC'] == '2'\n",
    "                        ), 'MARITAL_STATUS_CODE'] = 'S'\n",
    "\n",
    "hh_demographic_fxd.loc[(hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'U') &\n",
    "                       (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '4') &\n",
    "                       (hh_demographic_fxd['KID_CATEGORY_DESC'] == '3+'\n",
    "                        ), 'MARITAL_STATUS_CODE'] = 'S'\n",
    "\n",
    "hh_demographic_fxd.loc[(hh_demographic_fxd['MARITAL_STATUS_CODE'] == 'U') &\n",
    "                       (hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] == '1') &\n",
    "                       (hh_demographic_fxd['KID_CATEGORY_DESC'] ==\n",
    "                        'None/Unknown'), 'MARITAL_STATUS_CODE'] = 'S'\n",
    "\n",
    "hh_demographic_fxd = hh_demographic_fxd[\n",
    "    hh_demographic_fxd['MARITAL_STATUS_CODE'] != 'U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for marital_status in np.sort(hh_demographic_fxd['MARITAL_STATUS_CODE'].unique()):\n",
    "    print(\"Marital status:\", marital_status)\n",
    "    \n",
    "    hh_demographic_current_marital = hh_demographic_fxd[\n",
    "        hh_demographic_fxd['MARITAL_STATUS_CODE'] == marital_status]\n",
    "    \n",
    "    print(\n",
    "        hh_demographic_current_marital.groupby(\n",
    "            ['HH_COMP_DESC', 'HOUSEHOLD_SIZE_DESC',\n",
    "             'KID_CATEGORY_DESC']).size())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of entries goes from {len(hh_demographic.count(axis='columns')):n} to {len(hh_demographic_fxd.count(axis='columns')):n}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic_fxd.drop(['HH_COMP_DESC'], axis=1, inplace=True)\n",
    "\n",
    "hh_demographic_fxd.loc[hh_demographic_fxd['KID_CATEGORY_DESC'] ==\n",
    "                       'None/Unknown', 'KID_CATEGORY_DESC'] = '0'\n",
    "\n",
    "hh_demographic_fxd.rename(columns={'KID_CATEGORY_DESC': 'KIDS_DESC'},\n",
    "                          inplace=True)\n",
    "\n",
    "hh_demographic_fxd['KIDS_DESC'] = hh_demographic_fxd['KIDS_DESC'].fillna('0')\n",
    "\n",
    "hh_demographic_fxd.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the fixed dataframe:\n",
    "if not os.path.exists(\"saved_structures\"):\n",
    "    os.makedirs(\"saved_structures\")\n",
    "hh_demographic_fxd.to_csv(\"saved_structures/hh_demographic_fix_hhcomp.csv\",\n",
    "                          sep='\\t',\n",
    "                          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion: \n",
    "42 entries were discarded because the marital status Single did not match with the household size / number of children or because, in the Unknown marital status, the household size and the number of children did not carry enough information to conclude something on the marital status. We carry on the rest of our data journey with this cleaned demographic dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographic distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed inconsistencies in household composition, we want to have a look at how much data is present for each category. For now, the categories in this data frame are not arranged in a meaningful way, meaning that if we would make some plots now, we would not have the age categories ranged in ascending or descending order for example. \n",
    "Thus, we first want to arrange them, before making some exploratory plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going make the columns in the dataframe with categories of the ordered categorical type:\n",
    "hh_demographic_fxd['AGE_DESC'] = dem_fx.order_hh_dem(\n",
    "    hh_demographic_fxd, 'AGE_DESC',\n",
    "    ['19-24', '25-34', '35-44', '45-54', '55-64', '65+'])\n",
    "\n",
    "hh_demographic_fxd['INCOME_DESC'] = dem_fx.order_hh_dem(\n",
    "    hh_demographic_fxd, 'INCOME_DESC', \n",
    "    ['Under 15K', '15-24K', '25-34K', '35-49K', '50-74K', '75-99K',\n",
    "        '100-124K', '125-149K', '150-174K', '175-199K', '200-249K', '250K+'])\n",
    "\n",
    "hh_demographic_fxd['HOMEOWNER_DESC'] = dem_fx.order_hh_dem(\n",
    "    hh_demographic_fxd, 'HOMEOWNER_DESC',\n",
    "    ['Unknown', 'Probable Renter', 'Renter', 'Probable Owner', 'Homeowner'])\n",
    "\n",
    "hh_demographic_fxd['HOUSEHOLD_SIZE_DESC'] = dem_fx.order_hh_dem(\n",
    "    hh_demographic_fxd, 'HOUSEHOLD_SIZE_DESC', ['1', '2', '3', '4', '5+'])\n",
    "\n",
    "hh_demographic_fxd['KIDS_DESC'] = dem_fx.order_hh_dem(\n",
    "    hh_demographic_fxd, 'KIDS_DESC', ['0', '1', '2', '3+'])\n",
    "\n",
    "hh_demographic_fxd['MARITAL_STATUS_CODE'] = dem_fx.order_hh_dem(\n",
    "    hh_demographic_fxd, 'MARITAL_STATUS_CODE', ['M', 'S', 'U'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the categories in this data frame are ranged in a meaningful way, let's make some simple plots to have an idea of the characteristics of the population which we study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_fx.plot_demographics(hh_demographic_fxd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on graph**: We see that we don't have uniformly distributed demographic data. We know now that: \n",
    "- Age: most of our households are between 35-54 years old. We note though that we are not sure who's age this represent. Most of the time, it's the age of the male of the house when there are two adults. For single households it would be the adult's age. This just needs to be remembered. We do not have an idea of the age of everyone in our data. \n",
    "- Marital status: most households are married though we also have a lot of singles.\n",
    "- Household size: majority of households of 2 or 1 people/person. \n",
    "- Income: most people between 35-75 K (the average American income is 50 K so this seems all right)\n",
    "- Homeowner: most households are homeowners, still a lot of unknowns though. \n",
    "- Kids: Most households do not have kids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product data: \n",
    "Information on each product sold such as type of product, national or private label and a brand identifier. The attributes of the dataset are the following: \n",
    "- PRODUCT_ID: **unique**, identifies product\n",
    "- DEPARMENT: groups similar products together\n",
    "- COMMODITY_DESC: groups similar products together at a lower level\n",
    "- SUB_COMMODITY_DESC: groups similar products together at the lowest level. \n",
    "- MANUFACTURER: code that links products with the same manufacturer together \n",
    "- BRAND: indicates private or national label brand\n",
    "- CURR_SIZE_OF_PRODUCT: indicates package size (not available for all) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of products: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are \" + f\"{product.count()['PRODUCT_ID']:,d}\" +\n",
    "      \" products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Product departments: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there are \" + f\"{len(product['DEPARTMENT'].unique()) :,d}\" +\n",
    "      \" department categories\")\n",
    "print(\"The different categories are:\", product['DEPARTMENT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Representation of products in transactions: \n",
    "There are 92 353 products. As for the households, we can investigate whether all the products are represented in the *transaction_data* table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \" + f\"{len(transaction_data['PRODUCT_ID'].unique()):,d}\" +\n",
    "      \" products in the transactions table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 92 339 products represented in the *transaction_data* table, meaning that only **14** are not represented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of all products purchased by households during the study. Each line in the table is what could essentially be found in a store reciept. The attributes of the dataset are the following: \n",
    "\n",
    "- HOUSEHOLD_KEY: identifies each household, \n",
    "- BASKET_ID: identifies a purchase occasion, \n",
    "- DAY: day when transaction occured\n",
    "- PRODUCT_ID: identifies each product, \n",
    "- QUANTITY: Number of products purchased during trip\n",
    "- SALES_VALUE: Amount of dollars retailer recieves from sale\n",
    "- STORE_ID: identifies store, \n",
    "- COUPON_MATCH_DISC: discount applied du to retailer's match of manufacturer coupon\n",
    "- COUPON_DISC: discount applied due to manufacturer coupon\n",
    "- RETAIL_DISC: discount applied due to retailer's loyalty card program\n",
    "- TRANS_TIME: time of day when transaction occured\n",
    "- WEEK_NO: week of the transaction. Ranges from 1-102. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the coupons columns as we're not interessed in marketing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_initial_clean = transaction_data.drop(\n",
    "    ['COUPON_DISC', 'COUPON_MATCH_DISC', 'RETAIL_DISC'], axis=1)\n",
    "\n",
    "trans_initial_clean_hous_ind = trans_initial_clean[\n",
    "    'household_key'].sort_values().unique()\n",
    "\n",
    "trans_initial_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick overview: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of total transactions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there were \" +\n",
    "      f\"{transaction_data.count()['household_key']:,d}\" +\n",
    "      \" transactions during the two years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of total purchase occasions: \n",
    "Attention : here transactions are not what we usually think of. It's like on a receipt so the number of total unique purchases is not the number of transactions but the total of unique basket_id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there were \" +\n",
    "      f\"{len(transaction_data['BASKET_ID'].unique()):,d}\" +\n",
    "      \" purchase occasions during the two years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of households in transaction dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In total there were \" +\n",
    "      f\"{len(transaction_data['household_key'].unique()):,d}\" +\n",
    "      \" households represented during the two years.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data looks like the following:\n",
    "transaction_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Favored product departments and labels:\n",
    "Use dataset with new labeled product info from Product notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset with updated product labels:\n",
    "#labelled_prod = pd.read_csv('saved_structures/updated_prod.csv', sep='\\t')\n",
    "labelled_prod = pd.read_csv('../data/dunnhumby_complete_csv/updated_prod3.csv', sep='\\t')\n",
    "\n",
    "#Drop columns we are not interested in\n",
    "labelled_prod = labelled_prod.set_index('PRODUCT_ID').drop(\n",
    "    ['MANUFACTURER', 'BRAND', 'CURR_SIZE_OF_PRODUCT'], axis=1)\n",
    "labelled_prod.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What departments and labels were used in our transaction data ?\n",
    "We assume that most transactions fall in the department of grocery and drug GM (general merchandise). Let's see if we're right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_trans = trans_initial_clean.join(other=labelled_prod,\n",
    "                                          on='PRODUCT_ID').dropna()\n",
    "plt_fx.cat_count_plot(\n",
    "    labelled_trans['DEPARTMENT'],\n",
    "    'Number of occurences per department in our transaction data')\n",
    "\n",
    "plt_fx.cat_count_plot(\n",
    "    labelled_trans['LABEL'],\n",
    "    'Number of occurences per label in our transaction data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on graph**: Like we predicted, most of the transactions that occurred during the two year study were groceries, drug and general merchandise or Produce. Here we need to point out the \"PROCESSED FOODS\" is a label for everything food related that is not fresh produce (vegetables, dairy, meat, etc) in groceries like Honey, Cookies, Muffins, ready made dinners, dips, etc. It's of course also a label for fast food from the deli. We can see that in the next table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_prod[labelled_prod['LABEL'] == 'PROCESSED FOODS'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to look at how much households spend on groceries we're going to keep only transactions that are in the department of drug and general merchandise, groceries or produce (meat, deli and packaged meat included). We defined general merchandise as a broad catchall term for pretty much everything that's not groceries – from hearing aid batteries to major appliances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter transaction data to contain only the major departments:\n",
    "list_of_departments = ['GROCERY', 'DRUG GM', 'PRODUCE', 'MEAT', 'MEAT-PCKGD', 'DELI']\n",
    "\n",
    "trans_clean = labelled_trans[labelled_trans['DEPARTMENT'].apply(\n",
    "    lambda x: x in list_of_departments)]\n",
    "\n",
    "trans_clean_hous_ind = trans_clean['household_key'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shopping frequencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the assumption here that a year is 51 weeks. We could have also looked at the days but weeks was easier as there are 102 weeks in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Households per year:\n",
    "trans_clean_year_1 = trans_clean[trans_clean['WEEK_NO'].apply(\n",
    "    lambda x: x <= 51)]\n",
    "trans_clean_year_2 = trans_clean[trans_clean['WEEK_NO'].apply(\n",
    "    lambda x: x > 51)]\n",
    "\n",
    "#Get the household indices for each year:\n",
    "trans_clean_hous_ind_1 = trans_clean_year_1['household_key'].sort_values().unique()\n",
    "trans_clean_hous_ind_2 = trans_clean_year_2['household_key'].sort_values().unique()\n",
    "\n",
    "purch_per_household_year1 = trns.trans_per_year(\n",
    "    trans_clean_year_1, trans_clean_hous_ind_1)\n",
    "purch_per_household_year2 = trns.trans_per_year(\n",
    "    trans_clean_year_2, trans_clean_hous_ind_2)\n",
    "\n",
    "print('Mean of total purchases in the first year per household is %d purchases per year'\n",
    "    % purch_per_household_year1['total purchase per year'].mean())\n",
    "print('Median of total purchases in the first year per household is %d purchases per year'\n",
    "    % purch_per_household_year1['total purchase per year'].median())\n",
    "print('\\n')\n",
    "print('Mean of total purchases in the second year per household is %d purchases per year'\n",
    "    % purch_per_household_year2['total purchase per year'].mean())\n",
    "print('Median of total purchases in the second year per household is %d purchases per year'\n",
    "    % purch_per_household_year2['total purchase per year'].median())\n",
    "\n",
    "#Plot distribution if we want to look at them:\n",
    "titles = [\n",
    "    'Distribution of total purchases over the first year per household',\n",
    "    'Distribution of total purchaes over the second year per household']\n",
    "xlabels = [\n",
    "    'Number of total purchases in the first year',\n",
    "    'Number of total purchases in the second year']\n",
    "\n",
    "plt_fx.double_plot_box_dist(\n",
    "    purch_per_household_year1['total purchase per year'],\n",
    "    purch_per_household_year2['total purchase per year'], titles, xlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion for this part: \n",
    "We learned that, though the mean of households goes shopping approximately once per week, half of the households goes shopping less than once per week (through the median). Usually, if households did all their shopping at this retailer, we would assume that they should buy groceries at least every week in average. So we can guess already here that those households probably also do their shopping elsewhere than just this particular retailer. To confirm this we need to look at how much households spend and their specific participation length in the study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participation rate in the study:\n",
    "E.g. did all households participate during two years ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataframes of spending per household (how much they paid for each purchase)\n",
    "#for each year and in total over both years:\n",
    "\n",
    "grouped_trans_spent_total = trns.spending_per_household_per_trans(\n",
    "    trans_clean)\n",
    "grouped_trans_spent_year1 = trns.spending_per_household_per_trans(\n",
    "    trans_clean_year_1)\n",
    "grouped_trans_spent_year2 = trns.spending_per_household_per_trans(\n",
    "    trans_clean_year_2)\n",
    "\n",
    "grouped_trans_spent_year1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if all households are present both years:\n",
    "missing_households_year1 = set(list(range(1, 2501))).difference(\n",
    "    set(trans_clean_year_1['household_key'].unique()))\n",
    "\n",
    "missing_households_year2 = set(list(range(1, 2501))).difference(\n",
    "    set(trans_clean_year_2['household_key'].unique()))\n",
    "\n",
    "print(\n",
    "    \"The following households are not represented in the first year transaction data: \",\n",
    "    missing_households_year1)\n",
    "print(\n",
    "    \"The following households are not represented in the second year transaction data: \",\n",
    "    missing_households_year2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pandas dataframe with participation length per household key:\n",
    "participation_per_hh = pd.DataFrame(\n",
    "    index=trans_clean_hous_ind,\n",
    "    data={\n",
    "        'participation_length': [\n",
    "            len(grouped_trans_spent_total.loc[i]['WEEK_NO'].unique())\n",
    "            for i in trans_clean_hous_ind\n",
    "        ]\n",
    "    })\n",
    "\n",
    "#Plot participation:\n",
    "plt_fx.plot_box_dist(\n",
    "    participation_per_hh['participation_length'],\n",
    "    'Distribution of participation duration in the study',\n",
    "    'Lenght of participation [weeks]')\n",
    "\n",
    "print(\n",
    "    f\"There were {len(participation_per_hh[participation_per_hh['participation_length'] >= 100]):n} households that participated two years.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion for this part: \n",
    "We realize that some households were not present in the first year and some other dropped out of the study in the second year. But actually, we see that most households only participated between 20 and 80 weeks. Only 3 households did over 100 weeks. For now we are going to keep all households and not filter them on participation length because we don't know if participation is correlated with shopping trends. We just need to keep this in mind. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Household spending:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yearly spending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes of how much families spent per year (for year 1, 2 and for the mean of both years):\n",
    "budget_first_year = trns.bud_total_per_year(grouped_trans_spent_year1,\n",
    "                                            trans_clean_hous_ind_1)\n",
    "\n",
    "budget_second_year = trns.bud_total_per_year(grouped_trans_spent_year2,\n",
    "                                             trans_clean_hous_ind_2)\n",
    "\n",
    "#Dataframes of mean yearly spending:\n",
    "mean_yearly_spend = trns.mean_yearly_spending(budget_first_year,\n",
    "                                              budget_second_year)\n",
    "\n",
    "mean1 = budget_first_year['yearly spending'].mean()\n",
    "median1 = budget_first_year['yearly spending'].median()\n",
    "\n",
    "mean2 = budget_second_year['yearly spending'].mean()\n",
    "median2 = budget_second_year['yearly spending'].median()\n",
    "\n",
    "print('Mean of budget in the first year per household is ' +\n",
    "      f\"{round(mean1, 2):,}\" + ' dollars per year')\n",
    "print('Median of budget in the first year per household is ' +\n",
    "      f\"{round(median1, 2):,}\" + ' dollars per year')\n",
    "print('\\n')\n",
    "print('Mean of budget in the second year per household is ' +\n",
    "      f\"{round(mean2, 2):,}\" + ' dollars per year')\n",
    "print('Median of budget in the second year per household is ' +\n",
    "      f\"{round(median2, 2):,}\" + ' dollars per year')\n",
    "\n",
    "titles = [\n",
    "    'Amount spent per household in the first year',\n",
    "    'Amount spent per household in the second year'\n",
    "]\n",
    "xlabels = ['Amount spent per year', 'Amount spent per year']\n",
    "\n",
    "plt_fx.double_plot_box_dist(budget_first_year['yearly spending'],\n",
    "                            budget_second_year['yearly spending'], titles,\n",
    "                            xlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion for this part: \n",
    "Most families during the two years spent between ~400 dollars to 2000 dollars per year. We see though that there are outliers households that spent over 4000 dollars. It would be interesting to see if those are families with higher income or something else that demographically differentiates them from the rest. But first as 400 dollars per year does not make a lot of sense in term of regular spending at a retailer, we need to have an idea of how much households spent per week in average as it is easier to relate to than yearly spending. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weekly spending:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define average weekly spending as the total amount of money spent per household divided by the number of weeks they participated. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_budget_week = trns.df_weekly_spending(trans_clean)\n",
    "\n",
    "mean = [\n",
    "    mean_yearly_spend['mean yearly spending'].mean(),\n",
    "    mean_budget_week['mean weekly spending'].mean()\n",
    "]\n",
    "\n",
    "median = [\n",
    "    mean_yearly_spend['mean yearly spending'].median(),\n",
    "    mean_budget_week['mean weekly spending'].median()\n",
    "]\n",
    "\n",
    "print('Mean of weekly budget per family ' + f\"{round(mean[1], 2):,}\" +\n",
    "      ' dollars per week')\n",
    "print('Median of weekly budget per family is ' + f\"{round(median[1], 2):,}\" +\n",
    "      ' dollars per week')\n",
    "\n",
    "plt_fx.double_plot_box_dist(\n",
    "    mean_yearly_spend['mean yearly spending'],\n",
    "    mean_budget_week['mean weekly spending'],\n",
    "    ['Mean yearly amount per household', 'Weekly amount spent per household'],\n",
    "    ['Yearly spending [$]', 'Weekly spending [$]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There were {len(mean_budget_week[mean_budget_week['mean weekly spending'] < 50]):n} households with a budget under 50 dollars per week.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There were {len(mean_budget_week[mean_budget_week['mean weekly spending'] > 120]):n} households with a budget over 120 dollars per week.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion for this part: \n",
    "We notice that most households spend between \\\\$50-100 per week on purchases. We notice that a lot of households spent less than \\\\$50 per week. That seems to low for a weekly budget of full groceries as the weekly amount set by \"[Business insider:]( https://www.businessinsider.com/what-americans-spend-on-groceries-every-month-2019-4?r=US&IR=T#22-dallas-fort-worth-1)\" for the US is around \\\\$70. This again confirms that households do only part of their shopping at this retailer. Let's have a look at what households spend according to their income: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average spending versus income:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Load the clean demographic dataset from Marco:\n",
    "\n",
    "demographic_df = pd.read_csv('saved_structures/hh_demographic_fix_hhcomp.csv',\n",
    "                             sep='\\t')\n",
    "\n",
    "demographic_df = demographic_df.set_index('household_key')\n",
    "\"\"\"\n",
    "\n",
    "demographic_df = hh_demographic_fxd\n",
    "demographic_df = demographic_df.set_index('household_key')\n",
    "\n",
    "#Make categorical variables: \n",
    "demographic_df['INCOME_DESC'] = dem_fx.order_hh_dem(\n",
    "    demographic_df, 'INCOME_DESC', [\n",
    "        'Under 15K', '15-24K', '25-34K', '35-49K', '50-74K', '75-99K',\n",
    "        '100-124K', '125-149K', '150-174K', '175-199K', '200-249K', '250K+'\n",
    "    ])\n",
    "\n",
    "demographic_df['HOUSEHOLD_SIZE_DESC'] = dem_fx.order_hh_dem(\n",
    "    demographic_df, 'HOUSEHOLD_SIZE_DESC', ['1', '2', '3', '4', '5+'])\n",
    "\n",
    "demographic_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new demographic data frame where a column with mean yearly and weekly budget are added. We note though that there are only 759 demographic entries. That means that we can only look at the demographic information of part of the households above as for transactions we considered 2500 households. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with weekly and yearly spending:\n",
    "#The yearly spending is the mean over the two years\n",
    "\n",
    "hh_spending = mean_budget_week.join(mean_yearly_spend).dropna()\n",
    "\n",
    "hh_spending = hh_spending.join(demographic_df).dropna()\n",
    "\n",
    "print(\n",
    "    f\"Note: There are {len(hh_spending.index):n} in this new dataframe not 2500 households\"\n",
    ")\n",
    "\n",
    "#Save to csv:\n",
    "if not os.path.exists(\"saved_structures\"):\n",
    "    os.makedirs(\"saved_structures\")\n",
    "hh_spending.to_csv(\"saved_structures/hh_spending.csv\", sep='\\t', index=False)\n",
    "\n",
    "hh_spending.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the weekly and yearly spending versus income for each income category: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Yearly spending versus income', 'Weekly spending versus income']\n",
    "\n",
    "print(\n",
    "    f\"The mean of yearly spending per household is {hh_spending['mean yearly spending'].mean():n}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The mean of weekly spending per household is {hh_spending['mean weekly spending'].mean():n}.\"\n",
    ")\n",
    "\n",
    "plt_fx.double_categorical_scatter(hh_spending['INCOME_DESC'],\n",
    "                                  hh_spending['mean yearly spending'],\n",
    "                                  hh_spending['INCOME_DESC'],\n",
    "                                  hh_spending['mean weekly spending'],\n",
    "                                  titles,\n",
    "                                  add_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comment: \n",
    "We note that weekly spending and income does not augment linearly. We might have thought that a higher income creates higher spending habits but from what we see here it does not seem like it. For now it looks like the average spending at this retailer is not regular per income levels. Again this hints that the part of households that do most of their shopping at this retailer or only part of it varies greatly among all income levels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Low weekly spending vs participation length: \n",
    "We look at the relation between weekly spending and participation length. This might indicate that those households did not participate a lot in the study and that their data cannot be considered because they might not give any information about shopping habits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with participation length added to demographic data:\n",
    "participation_hh_dem = participation_per_hh.join(hh_spending).dropna()\n",
    "\n",
    "#Look at households that spend under 25 dollars per week:\n",
    "under25 = participation_hh_dem[\n",
    "    participation_hh_dem['mean weekly spending'] <= 25]\n",
    "\n",
    "#Plot participation versus income:\n",
    "titles = [\n",
    "    'Income versus mean weekly spending for households with low spending',\n",
    "    'Income versus study participation length for households with low spending'\n",
    "]\n",
    "\n",
    "plt_fx.double_categorical_scatter(under25['INCOME_DESC'],\n",
    "                                  under25['mean weekly spending'],\n",
    "                                  under25['INCOME_DESC'],\n",
    "                                  under25['participation_length'], titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comment on graph:\n",
    "We note that households with low weekly spending still participated for at least around 40 weeks so we cannot say that those households just partcipated once and did it \"badly\" and that their data cannot be taken into account when looking for shopping trends. But still, some households with 35-49K income spent below 12 dollars per week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Loyal\" shoppers ? \n",
    "By loyal we mean that they might do most of their shopping at this retailer. In a perfect world, to get information about food habits from these household transactions, we would need all households to do most of their grocery shopping at this retailer. For this wee need information about usual grocery spending habits, we use statistics available online: <br>\n",
    "\n",
    "According to the [Bureau of Labor statistics:](https://www.thestreet.com/personal-finance/average-cost-of-food-14845479)\n",
    "- Food spending: more than \\\\$7'7000 per year on groceries and more .\n",
    "    - one member household : \\\\$4,425\n",
    "    - Two members : \\\\$7,865\n",
    "    - Four members : \\\\$10,995\n",
    "- Income levels: attention groceries do not include eating-out ! \n",
    "    - lowest 20%: Mean Income of \\\\$11,394 -> \\\\$2,582 on groceries per year. **On what kind of produce do they spend it ?**\n",
    "    - second 20%: Mean income \\\\$29,821 -> \\\\$3,622 on groceries per year. \n",
    "    - third 20%: Mean income \\\\$52,431 -> \\\\$4,038 on groceries per year. \n",
    "    - fourth 20%: Mean Income of \\\\$86,363 -> \\\\$4,893 on groceries\n",
    "    - top 20%: Mean Income of \\\\$188,103 -> \\\\$6,677 on groceries\n",
    "    \n",
    "<br>\n",
    "So we know that in our data, every household (in the lower income tier) should have spent at least around \\$2500 dollars per year. Households that spent less than that did not participate in the study fully and bought groceries elsewhere. We thus make the assumption that to be a \"loyal\" shopper, they should spend at least \\$2500 per year. We set the same bound for everyone for the moment just in case we have some really frugal households in higher income categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove in the dataset:\n",
    "filtered_income = participation_hh_dem[\n",
    "    participation_hh_dem['mean yearly spending'] >= 2500]\n",
    "\n",
    "print(\n",
    "    f\"We lost {len(participation_hh_dem.index) - len(filtered_income.index):d} households by filtering.\"\n",
    ")\n",
    "print(\n",
    "    f\"We have {len(filtered_income.index):d} households left after filtering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles1 = [\n",
    "    'Income versus mean yearly spending for households with spending > 2500',\n",
    "    'Income versus study participation length for households with spending > 2500'\n",
    "]\n",
    "\n",
    "plt_fx.double_categorical_scatter(filtered_income['INCOME_DESC'],\n",
    "                                  filtered_income['mean yearly spending'],\n",
    "                                  filtered_income['INCOME_DESC'],\n",
    "                                  filtered_income['participation_length'],\n",
    "                                  titles)\n",
    "\n",
    "titles2 = [\n",
    "    'Age versus mean yearly spending for households with spending >2500',\n",
    "    'Household size versus yearly spending for households with spending > 2500'\n",
    "]\n",
    "\n",
    "plt_fx.double_categorical_scatter(filtered_income['AGE_DESC'],\n",
    "                                  filtered_income['mean yearly spending'],\n",
    "                                  filtered_income['HOUSEHOLD_SIZE_DESC'],\n",
    "                                  filtered_income['mean yearly spending'],\n",
    "                                  titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comment: \n",
    "We don't have that many \"loyal\" shoppers (only 286 on 800) but at least we can see that most of those households participated for more than a year. Still the real number of \"loyal\" households is probably lower as there are households of 5+ that spent less than 3K/year which seems unreasonable if that is their only shopping. <br> \n",
    "**Note**: We see that there are some outliers, like households with income under 15K that spent around 8K per year on groceries. That seems like a miss-classification (probably wrong income). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion for this part:\n",
    "We learned that there are two categories of shoppers at this retailer; those that do most of their grocery shopping there every week and those who only do part of it. From this we want to know if we can find trends between what households shop and their demographic information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shopping trends and correlations:\n",
    "- what did they buy weekly of each label\n",
    "- how much did they spend on each label per week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for correlation calulcations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have two interesting dataframes:\n",
    "#The demographic data for each household and their weekly spending, yearly spending and participation in the study.\n",
    "#print(participation_hh_dem.head(4))\n",
    "\n",
    "#The transactions of all households and the labels of each product.\n",
    "#print(trans_clean.head(4))\n",
    "\n",
    "print(f\"There are {len(trans_clean['LABEL'].unique()):n} unique labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weekly purchases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table with demographic data and number of weekly purchases for each produce label to get an idea of their average grocery shopping carts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_cart_df = trns.create_weekly_cart_df(trans_clean, participation_per_hh)\n",
    "\n",
    "#Drop the column of unfound labels as it's just missing information\n",
    "weekly_cart_df = weekly_cart_df.drop('not found_QUANT', axis = 1)\n",
    "\n",
    "#Save it to csv:\n",
    "if not os.path.exists(\"saved_structures\"):\n",
    "    os.makedirs(\"saved_structures\")\n",
    "\n",
    "weekly_cart_df.to_csv(\"saved_structures/weekly_cart_df.csv\",\n",
    "                      sep='\\t',\n",
    "                      index=False)\n",
    "\n",
    "weekly_cart_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are a lot of labels which have very low values of weekly buying,we drop them for the rest of the analysis. Thus, we are going to filter out the labels, and keep only the 7 labels which represent most frequently bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_labels = trans_clean.groupby(\"LABEL\").count().sort_values(\n",
    "    by=\"PRODUCT_ID\", ascending=False).iloc[:7].index.tolist()\n",
    "\n",
    "#filtered_labels:\n",
    "trans_clean_filtered_labels = trans_clean.loc[trans_clean[\"LABEL\"].isin(\n",
    "    filtered_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_fx.cat_count_plot(\n",
    "    trans_clean_filtered_labels['LABEL'],\n",
    "    'Number of occurences per label in our filtered transaction data (only the most frequent labels in the most frequent departments)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 7 labels which are the most frequent in the baskets.\n",
    "\n",
    "We now want to find also, for these 7 most frequent labels, the quantity which is bought weekly and per household on each of these labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_cart_df_filtered_labels = trns.create_weekly_cart_df(\n",
    "    trans_clean_filtered_labels, participation_per_hh)\n",
    "\n",
    "#Save it to csv:\n",
    "if not os.path.exists(\"saved_structures\"):\n",
    "    os.makedirs(\"saved_structures\")\n",
    "\n",
    "weekly_cart_df_filtered_labels.to_csv(\n",
    "    \"saved_structures/weekly_cart_df_filtered_labels.csv\",\n",
    "    sep='\\t',\n",
    "    index=False)\n",
    "\n",
    "weekly_cart_df_filtered_labels.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weekly purchases and demographic information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the dataframe with demographic information and weekly shopping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_trans_df = participation_hh_dem.join(weekly_cart_df_filtered_labels)\n",
    "dem_trans_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between transactions and demographic information: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate correlation coefficients between labels and buyer's information. As there are categorical and continuous variables, we need to calculate coefficients differently. For this we use [this](https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9) documentation to calculate a cramer correlation and correlation ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_trans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_col = [\n",
    "    'participation_length', 'mean weekly spending', 'mean yearly spending',\n",
    "    'AGE_DESC', 'MARITAL_STATUS_CODE', 'INCOME_DESC', 'HOMEOWNER_DESC',\n",
    "    'HOUSEHOLD_SIZE_DESC', 'KIDS_DESC', 'PRODUCE_QUANT',\n",
    "    'PROCESSED FOODS_QUANT', 'MEAT & SEAFOOD_QUANT', 'DAIRY_QUANT',\n",
    "    'BEVERAGES_QUANT', 'HOUSEHOLDS_QUANT', 'CONDIMENTS_QUANT'\n",
    "]\n",
    "\n",
    "#Create dictionnary to indicate which columns are categorical or continous\n",
    "cat_col = {\n",
    "    'participation_length': 0,\n",
    "    'mean weekly spending': 0,\n",
    "    'mean yearly spending': 0,\n",
    "    'AGE_DESC': 1,\n",
    "    'MARITAL_STATUS_CODE': 1,\n",
    "    'INCOME_DESC': 1,\n",
    "    'HOMEOWNER_DESC': 1,\n",
    "    'HOUSEHOLD_SIZE_DESC': 1,\n",
    "    'KIDS_DESC': 1,\n",
    "    'PRODUCE_QUANT': 0,\n",
    "    'PROCESSED FOODS_QUANT': 0,\n",
    "    'MEAT & SEAFOOD_QUANT': 0,\n",
    "    'DAIRY_QUANT': 0,\n",
    "    'BEVERAGES_QUANT': 0,\n",
    "    'HOUSEHOLDS_QUANT': 0,\n",
    "    'CONDIMENTS_QUANT': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the correlation matrix, depending on the type of variables \n",
    "we use different correlation calculations:\n",
    "- categorical vs categorical : cramer correlation \n",
    "- categorical vs continous : correlation ratio\n",
    "- continuous vs continuous : \n",
    "\"\"\"\n",
    "corr_matrix_body = pd.DataFrame(index=list_of_col,\n",
    "                                columns=list_of_col,\n",
    "                                dtype=np.float64)\n",
    "for item in list_of_col:\n",
    "    for subitem in list_of_col:\n",
    "        if cat_col[item] == 1 and cat_col[subitem] == 1:\n",
    "            corr_matrix_body[item][subitem] = trns.cramers_v(\n",
    "                dem_trans_df[item], dem_trans_df[subitem])\n",
    "        elif cat_col[item] == 1 and cat_col[subitem] == 0:\n",
    "            corr_matrix_body[item][subitem] = trns.correlation_ratio(\n",
    "                dem_trans_df[item], dem_trans_df[subitem])\n",
    "        elif cat_col[item] == 0 and cat_col[subitem] == 1:\n",
    "            corr_matrix_body[item][subitem] = trns.correlation_ratio(\n",
    "                dem_trans_df[subitem], dem_trans_df[item])\n",
    "        else:\n",
    "            corr_matrix_body[item][subitem] = stats.pearsonr(\n",
    "                dem_trans_df[subitem], dem_trans_df[item])[0]\n",
    "\n",
    "corr_matrix_body.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = sns.heatmap(corr_matrix_body, annot=True)\n",
    "\n",
    "ax.set_xticklabels(ax.get_xticklabels(),\n",
    "                   rotation=45,\n",
    "                   horizontalalignment='right')\n",
    "\n",
    "#this is because the map was cut off on the top and bottom somehow:\n",
    "ax.set_ylim(len(corr_matrix_body), -0.5)\n",
    "ax.set(title='Correlation between shopping habits and demographic information')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comment on graph:\n",
    "The lighter the color, the higher the correlation between two instances. We notice several groups of interest in our data: \n",
    "\n",
    "- **Among demographic parameters**: \n",
    "    - The number of kids is highly correlated (*0.91*) with household size\n",
    "    - The marital status is highly correlated (*0.92*) with the household size  <br>\n",
    "   \n",
    "   \n",
    "   \n",
    "- **Among transaction parameters:** \n",
    "    - Mean yearly spending is highly correlated to mean weekly spending but that is nothing new because weekly spending was calculated from yearly spending. \n",
    "    - There is a lighter group of correlation between weekly label quantities and mean weekly/yearly spending. The \"higher\" correlations (around *0.7*) are for the weekly quantities of produce, processed foods and household quantities. This implies that it is probable that a higher weekly spending is correlated with bigger quantities of those labels ? Nevertheless as the coefficient is lower than 0.8, we cannot really say that it is significant. \n",
    "    - There is a slight correlation of 0.66 between *Meat & Seafood* and *Processed Foods* but again it is not significant\n",
    "    \n",
    "    \n",
    "    \n",
    "- **Between demographic and transaction data:** there is no significant correlation between those categories. Correlation coefficients are extremely low and do not allow us to conclude any trend this way. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots for correlation between number of kids and household size and marital status and household size:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw 2 very high correlations among demographic data, we are going to look in more depth into it to understand the relationships between those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (18,6))\n",
    "\n",
    "sns.swarmplot(dem_trans_df[\"HOUSEHOLD_SIZE_DESC\"],\n",
    "              dem_trans_df[\"mean weekly spending\"],\n",
    "              hue = dem_trans_df[\"KIDS_DESC\"],\n",
    "              ax = ax[0])\n",
    "\n",
    "ax[0].set_title(\"Mean weekly spending according to the number of kids and to the household size\")\n",
    "\n",
    "sns.swarmplot(dem_trans_df[\"HOUSEHOLD_SIZE_DESC\"],\n",
    "              dem_trans_df[\"mean weekly spending\"],\n",
    "              hue = dem_trans_df[\"MARITAL_STATUS_CODE\"],\n",
    "              ax = ax[1])\n",
    "#ax[0,1] = fig2\n",
    "ax[1].set_title(\"Mean weekly spending according to the marital status and to the household size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comment: \n",
    "On the figure above, we plotted the mean weekly spending against the household size, and colored the points according to the number of kids in the first subfigure, and to the marital status code for the second subfigure. \n",
    "We did this to have a clearer view of how the categorical data are correlated, and it is easily observable on the figure, thanks to the colors. Thus, quite intuitively, a higher household size is correlated to a bigger number of kids, and to a marital status which is married."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration of the time of the day when the transactions are done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we will use the transaction_data table to calculate the time of the day when each household makes in average its transactions, and we will do an inner join of this table to the dem_trans_df table, so that we don't keep the household which have been previously filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_demographic = pd.read_csv(\n",
    "    '../data/dunnhumby_complete_csv/hh_demographic.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell is just here to get an idea of what the column 'TRANS_TIME' looks like.\n",
    "We undertand that we have an interger which represents the time of the day as such:\n",
    "2248 = 22h48\n",
    "623 = 06h23\n",
    "9 = 00h09\n",
    "We thus have to transform these intergers into meaningful time points.\"\"\"\n",
    "\n",
    "time = transaction_data.TRANS_TIME.unique()\n",
    "time = time.tolist()\n",
    "time.sort()\n",
    "#print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Note : this cell can take several minutes to run.\"\"\"\n",
    "\n",
    "temp = transaction_data[\"TRANS_TIME\"].astype(\"str\")\n",
    "for i in range(len(temp)):\n",
    "    #if i%100000 == 0:     serves as a counter if we want to know where we are \n",
    "        #print(i)\n",
    "    if len(temp[i]) == 3:\n",
    "        temp[i] = \"0\" + temp[i]\n",
    "    elif len(temp[i]) == 2:\n",
    "        temp[i] = \"00\" + temp[i]\n",
    "    elif len(temp[i]) == 1:\n",
    "        temp[i] = \"000\" + temp[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_data[\"TRANS_TIME_STR\"] = temp\n",
    "time = pd.to_datetime(transaction_data[\"TRANS_TIME_STR\"], format='%H%M').dt.time\n",
    "transaction_data[\"transaction_time_datetime\"] = time\n",
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"We plot the overall number of transactions depending on the time of the day.\"\n",
    "\n",
    "transaction_data[\"transaction_time_datetime\"].hist(bins = 24)\n",
    "hours = [datetime.time(i) for i in range(24)]\n",
    "plt.title(\"Total number of transactions according to the time of the day\")\n",
    "plt.xlabel(\"Time of the day\")\n",
    "plt.ylabel(\"Number of transactions\")\n",
    "plt.xticks(hours, rotation = 90)\n",
    "plt.axvline(tm_fx.avg_time(transaction_data[\"transaction_time_datetime\"]), \n",
    "            color='red', \n",
    "            linestyle='dashed', \n",
    "            linewidth=1, \n",
    "            label = \"average transaction time\")\n",
    "plt.legend(loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe on the figure above that the transactions occur mostly during the afternoon, on average around 17h. The moment of the day where we have the fewer transactions is around 5h in the morning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average transaction time per household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_hh = transaction_data.groupby(transaction_data.household_key)[\"transaction_time_datetime\"].apply(list)\n",
    "time_per_hh_df = pd.DataFrame(time_per_hh)\n",
    "time_per_hh_df.columns = [\"transaction_time_per_hh\"]\n",
    "time_per_hh_df[\"avg_transaction_time\"] = 'todo'\n",
    "time_per_hh_df[\"avg_transaction_time_in_seconds\"] = 'todo'\n",
    "#time_per_hh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,2501):\n",
    "    time_per_hh_df.avg_transaction_time[i] = tm_fx.avg_time(time_per_hh_df.transaction_time_per_hh[i])\n",
    "    time_per_hh_df.avg_transaction_time_in_seconds[i] = tm_fx.time_to_seconds(time_per_hh_df.avg_transaction_time[i])\n",
    "time_per_hh_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_trans_time_df = pd.merge(dem_trans_df, time_per_hh_df, how = \"inner\", left_index = True, right_index = True)\n",
    "dem_trans_time_df.avg_transaction_time_in_seconds[1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_col = [\n",
    "    'participation_length', 'mean weekly spending', 'mean yearly spending',\n",
    "    'AGE_DESC', 'MARITAL_STATUS_CODE', 'INCOME_DESC', 'HOMEOWNER_DESC',\n",
    "    'HOUSEHOLD_SIZE_DESC', 'KIDS_DESC', 'PRODUCE_QUANT',\n",
    "    'PROCESSED FOODS_QUANT', 'MEAT & SEAFOOD_QUANT', 'DAIRY_QUANT',\n",
    "    'BEVERAGES_QUANT', 'HOUSEHOLDS_QUANT', 'CONDIMENTS_QUANT', 'avg_transaction_time_in_seconds'\n",
    "]\n",
    "\n",
    "#Create dictionnary to indicate which columns are categorical or continous\n",
    "cat_col = {\n",
    "    'participation_length': 0,\n",
    "    'mean weekly spending': 0,\n",
    "    'mean yearly spending': 0,\n",
    "    'AGE_DESC': 1,\n",
    "    'MARITAL_STATUS_CODE': 1,\n",
    "    'INCOME_DESC': 1,\n",
    "    'HOMEOWNER_DESC': 1,\n",
    "    'HOUSEHOLD_SIZE_DESC': 1,\n",
    "    'KIDS_DESC': 1,\n",
    "    'PRODUCE_QUANT': 0,\n",
    "    'PROCESSED FOODS_QUANT': 0,\n",
    "    'MEAT & SEAFOOD_QUANT': 0,\n",
    "    'DAIRY_QUANT': 0,\n",
    "    'BEVERAGES_QUANT': 0,\n",
    "    'HOUSEHOLDS_QUANT': 0,\n",
    "    'CONDIMENTS_QUANT': 0,\n",
    "    'avg_transaction_time_in_seconds': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the correlation matrix, depending on the type of variables \n",
    "we use different correlation calculations:\n",
    "- categorical vs categorical : cramer correlation \n",
    "- categorical vs continous : correlation ratio\n",
    "- continuous vs continuous : \n",
    "\"\"\"\n",
    "corr_matrix_body_with_time = pd.DataFrame(index=list_of_col,\n",
    "                                          columns=list_of_col,\n",
    "                                          dtype=np.float64)\n",
    "for item in list_of_col:\n",
    "    for subitem in list_of_col:\n",
    "        print (item, subitem)\n",
    "        if cat_col[item] == 1 and cat_col[subitem] == 1:\n",
    "            corr_matrix_body_with_time[item][subitem] = trns.cramers_v(\n",
    "                dem_trans_time_df[item], dem_trans_time_df[subitem])\n",
    "        elif cat_col[item] == 1 and cat_col[subitem] == 0:\n",
    "            corr_matrix_body_with_time[item][subitem] = trns.correlation_ratio(\n",
    "                dem_trans_time_df[item], dem_trans_time_df[subitem])\n",
    "        elif cat_col[item] == 0 and cat_col[subitem] == 1:\n",
    "            corr_matrix_body_with_time[item][subitem] = trns.correlation_ratio(\n",
    "                dem_trans_time_df[subitem], dem_trans_time_df[item])\n",
    "        else:\n",
    "            corr_matrix_body_with_time[item][subitem] = stats.pearsonr(\n",
    "                dem_trans_time_df[subitem], dem_trans_time_df[item])[0]\n",
    "\n",
    "corr_matrix_body_with_time.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision trees and random forests: \n",
    "As it seems that we cannot find a trend based on one type of product bought weekly, we need to take into account the combination of weekly shopping of different labels. For this wee need to use some machine learning. We are going to try and fit a decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dataframe : We are going to use dem_trans_df with all labels except \"not_found\". \n",
    "dem_trans_df.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit decision tree: <br>\n",
    "- [link](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76)\n",
    "- [link2](https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c)\n",
    "- [link3](https://github.com/WillKoehrsen/Machine-Learning-Projects/blob/master/Random%20Forest%20Tutorial.ipynb)\n",
    "- [link4](https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.getdoc(ml_fx.decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [\n",
    "    'participation_length', 'mean weekly spending', 'mean yearly spending',\n",
    "    'PRODUCE_QUANT', 'HOUSEHOLDS_QUANT','PROCESSED FOODS_QUANT',\n",
    "    'MEAT & SEAFOOD_QUANT', 'DAIRY_QUANT', 'CONDIMENTS_QUANT',\n",
    "    'BEVERAGES_QUANT','MEAT & SEAFOOD_QUANT'\n",
    "]\n",
    "\n",
    "print('Decision tree on income:')\n",
    "income_tree = ml_fx.decision_tree('INCOME_DESC',features, dem_trans_df)\n",
    "print('')\n",
    "print('Decision tree on age:')\n",
    "age_tree = ml_fx.decision_tree('AGE_DESC',features, dem_trans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random forest on income:')\n",
    "ml_fx.random_forest('INCOME_DESC',features, dem_trans_df)\n",
    "print('')\n",
    "print('Random forest on age:')\n",
    "ml_fx.random_forest('AGE_DESC',features, dem_trans_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comment: \n",
    "We see that the random forest model performs slightly better for both income and age. Though the AUC score is just slightly above 0.5 which is really bad. \n",
    "\n",
    "**We should look what we have for other demographic parameters but it's probably just as bad. Maybe do a pca before ? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On other demographic parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_trans_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decision tree on marital status:')\n",
    "ml_fx.decision_tree('MARITAL_STATUS_CODE',features, dem_trans_df)\n",
    "print('')\n",
    "print('Decision tree on homeowner situation:')\n",
    "ml_fx.decision_tree('HOMEOWNER_DESC',features, dem_trans_df)\n",
    "print('Decision tree on household size:')\n",
    "ml_fx.decision_tree('HOUSEHOLD_SIZE_DESC',features, dem_trans_df)\n",
    "print('')\n",
    "print('Decision tree on number of kids:')\n",
    "ml_fx.decision_tree('KIDS_DESC',features, dem_trans_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, for the other demographic data, the AUC score is also around 0.5, which is bad. Even for the homeowner situation, which has the maximum AUC score, it is only 0.57."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random forest on marital status:')\n",
    "ml_fx.random_forest('MARITAL_STATUS_CODE',features, dem_trans_df)\n",
    "print('')\n",
    "print('Random forest on homeowner situation:')\n",
    "ml_fx.random_forest('HOMEOWNER_DESC',features, dem_trans_df)\n",
    "print('Random forest on household size:')\n",
    "ml_fx.random_forest('HOUSEHOLD_SIZE_DESC',features, dem_trans_df)\n",
    "print('')\n",
    "print('Random forest on number of kids:')\n",
    "ml_fx.random_forest('KIDS_DESC',features, dem_trans_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the same conclusions appear as for the decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization of the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dem_trans_df['INCOME_DESC'].sort_values().unique()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "\n",
    "income_tree = ml_fx.decision_tree('INCOME_DESC',features, dem_trans_df)\n",
    "\n",
    "\"\"\"Let's try it for the income for example. If it works, we can build a function in the modules, \n",
    "which saves the image as a png and displays it in the notebook.\"\"\"\n",
    "# Export as dot\n",
    "export_graphviz(income_tree, 'tree_income.dot', rounded = True, feature_names = features, class_names = class_names, filled = True)\n",
    "\n",
    "\"\"\"Here, in the functions which fit the models, we could add a return tree, in addition to printing the accuracies, so that\n",
    "we can then build the image of the decision tree and clearly see the groups.\n",
    "It means that to call the function, we could write tree_income = ml_fx.decision_tree('INCOME_DESC',features, dem_trans_df),\n",
    "and work on the tree_income.\"\"\"\n",
    "\n",
    "\n",
    "# Convert to png:\n",
    "#call(['dot', '-Tpng', 'tree_income.dot', '-o', 'tree.png', '-Gdpi=400']);\n",
    "#Display the image \n",
    "#Image('tree.png')\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (18,8))\n",
    "plot_tree(income_tree, max_depth=3,rounded = True, fontsize =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "440px",
    "left": "330px",
    "top": "220px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
